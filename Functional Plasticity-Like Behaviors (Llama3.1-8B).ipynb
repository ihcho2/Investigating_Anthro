{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba8b66b9",
   "metadata": {},
   "source": [
    "# 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53bc6e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ac30ab061c44bf84482d799f2cfe03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import snapshot_download\n",
    "from tuned_lens import TunedLens\n",
    "from tuned_lens.plotting import PredictionTrajectory\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\", device_map=\"auto\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\", \n",
    "                                                   device_map=\"auto\", \n",
    "                                                   torch_dtype=torch.float16)\n",
    "tokenizer.padding_side = \"right\"\n",
    "if tokenizer.pad_token is None:\n",
    "    # Safe choice: use eos as pad if no dedicated pad token\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a77c0a",
   "metadata": {},
   "source": [
    "# 2. Prepare Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3446f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from generate_prompts import return_model_prompts\n",
    "# prompts_all_parallel_multiple = return_model_prompts(model_name = \"google/gemma-2-9b-it\",\n",
    "#                                                      data_name = 'BFCL_v4_live_parallel_multiple.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72b619d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('../SAE_Summ/prompts_with_generation_cnndm.json', 'r') as file:\n",
    "#     prompts_with_generation_cnndm = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd3acdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('../SAE_Summ/prompts_with_generation_all_extractive_cnndm.json', 'r') as file:\n",
    "#     prompts_with_generation_all_extractive_cnndm = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99d74669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module.\n",
    "    # torch.set_deterministic(True)\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01100d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prompts = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c31ab",
   "metadata": {},
   "source": [
    "# 2.1 AGNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b895de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random \n",
    "\n",
    "dataset = load_dataset('ag_news', split=['train', 'test'])\n",
    "train_data_agnews = dataset[0]\n",
    "test_data_agnews = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89181e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples_per_label = 500\n",
    "\n",
    "label_demonstrations = {i:[] for i in range(4)}\n",
    "\n",
    "for i in range(len(train_data_agnews)):\n",
    "    label_demonstrations[train_data_agnews[i]['label']].append(i)\n",
    "    \n",
    "set_seed(42)\n",
    "\n",
    "remove_label = -1\n",
    "\n",
    "test_query_indices = []\n",
    "for i in range(len(label_demonstrations)):\n",
    "    if i == remove_label:\n",
    "        continue\n",
    "    test_query_indices.extend(random.sample(label_demonstrations[i], num_examples_per_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5cad3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_prompts['agnews'] = []\n",
    "\n",
    "for N in [16]:\n",
    "    num_labels = len(label_demonstrations)\n",
    "    \n",
    "    for i, tq_index in enumerate(test_query_indices):\n",
    "        set_seed(i)\n",
    "        \n",
    "        # 1. Use the query index 'i' to shift the starting label\n",
    "        # This ensures that for N=1, Query 0 gets Label 0, Query 1 gets Label 1, etc.\n",
    "        start_label_offset = i % num_labels\n",
    "        \n",
    "        shots_per_label = [N // num_labels] * num_labels\n",
    "        remainder = N % num_labels\n",
    "        \n",
    "        # Distribute the remainder starting from the offset\n",
    "        for r in range(remainder):\n",
    "            label_to_increment = (start_label_offset + r) % num_labels\n",
    "            shots_per_label[label_to_increment] += 1\n",
    "            \n",
    "        fse_indices = []\n",
    "        \n",
    "        # 2. Sample from each label\n",
    "        for l in range(num_labels):\n",
    "            needed = shots_per_label[l]\n",
    "            if needed == 0:\n",
    "                continue\n",
    "                \n",
    "            available_pool = [idx for idx in label_demonstrations[l] if idx != tq_index]\n",
    "            sampled = random.sample(available_pool, needed)\n",
    "            fse_indices.extend(sampled)\n",
    "            \n",
    "        # 3. Randomize the order of shots within the prompt\n",
    "        random.shuffle(fse_indices)\n",
    "        \n",
    "        prompt = 'Pretend that you are an expert in news topic classification. For a given news article, you have to assess the topic, determining whether it is world, sports, business, or technology.'\n",
    "\n",
    "        for j, fse_index in enumerate(fse_indices):\n",
    "            prompt += f'\\n\\nExample {j+1}'\n",
    "            prompt += f\"\\nArticle:\\n{train_data_agnews[fse_index]['text']}\"\n",
    "            prompt += f\"\\nTopic:\\n{train_data_agnews.features['label'].names[train_data_agnews[fse_index]['label']]}\"\n",
    "\n",
    "        prompt += f'\\n\\nExample {len(fse_indices)+1}'\n",
    "        prompt += f\"\\nArticle:\\n{train_data_agnews[tq_index]['text']}\"\n",
    "        prompt += f\"\\nTopic:\\n{train_data_agnews.features['label'].names[train_data_agnews[tq_index]['label']]}\"\n",
    "\n",
    "\n",
    "        all_prompts['agnews'].append(\"<bos><start_of_turn>user\\n\"+prompt.replace('Sci/Tech', 'Technology'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e440563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "all_prompts['agnews_controlled'] = {}\n",
    "\n",
    "remove_label = 3  # label-id to exclude entirely (e.g., 3)\n",
    "\n",
    "# --- label name helper (also fixes Sci/Tech -> Technology) ---\n",
    "label_names = list(train_data_agnews.features['label'].names)\n",
    "label_names = [(\"Technology\" if n == \"Sci/Tech\" else n) for n in label_names]\n",
    "\n",
    "# --- keep only labels != remove_label ---\n",
    "kept_labels = [l for l in range(len(label_demonstrations)) if l != remove_label]\n",
    "num_labels = len(kept_labels)\n",
    "\n",
    "# --- filter test queries so the target example is never remove_label ---\n",
    "filtered_test_query_indices = [\n",
    "    idx for idx in test_query_indices\n",
    "    if int(train_data_agnews[idx][\"label\"]) != remove_label\n",
    "]\n",
    "\n",
    "assert test_query_indices[:1500] == filtered_test_query_indices\n",
    "\n",
    "for N in [16]:\n",
    "    all_prompts['agnews_controlled'] = []\n",
    "\n",
    "    for i, tq_index in enumerate(filtered_test_query_indices):\n",
    "        set_seed(i)\n",
    "\n",
    "        # Balanced allocation across remaining labels only\n",
    "        start_label_offset = i % num_labels\n",
    "        shots_per_label = [N // num_labels] * num_labels\n",
    "        remainder = N % num_labels\n",
    "        for r in range(remainder):\n",
    "            shots_per_label[(start_label_offset + r) % num_labels] += 1\n",
    "\n",
    "        fse_indices = []\n",
    "\n",
    "        # Sample demonstrations from kept labels only\n",
    "        for local_li, label_id in enumerate(kept_labels):\n",
    "            needed = shots_per_label[local_li]\n",
    "            if needed == 0:\n",
    "                continue\n",
    "\n",
    "            available_pool = [idx for idx in label_demonstrations[label_id] if idx != tq_index]\n",
    "            if len(available_pool) == 0:\n",
    "                raise ValueError(f\"No available demos for label {label_id} after excluding tq_index={tq_index}\")\n",
    "\n",
    "            if len(available_pool) < needed:\n",
    "                # fallback: sample with replacement if pool too small\n",
    "                sampled = random.choices(available_pool, k=needed)\n",
    "            else:\n",
    "                sampled = random.sample(available_pool, needed)\n",
    "\n",
    "            fse_indices.extend(sampled)\n",
    "\n",
    "        # Shuffle shots within the prompt\n",
    "        random.shuffle(fse_indices)\n",
    "\n",
    "        # Instruction mentions only remaining classes\n",
    "        kept_label_names = [label_names[l] for l in kept_labels]\n",
    "        topics_str = \", \".join(kept_label_names[:-1]) + f\", or {kept_label_names[-1]}\"\n",
    "\n",
    "        prompt = (\n",
    "            \"Pretend that you are an expert in news topic classification. \"\n",
    "            f\"For a given news article, you have to assess the topic, determining whether it is {topics_str}.\"\n",
    "        )\n",
    "\n",
    "        # Add demonstrations (guaranteed not remove_label, since we sampled only kept_labels)\n",
    "        for j, fse_index in enumerate(fse_indices):\n",
    "            lbl = int(train_data_agnews[fse_index][\"label\"])\n",
    "            # Extra safety check\n",
    "            if lbl == remove_label:\n",
    "                continue\n",
    "\n",
    "            prompt += f\"\\n\\nExample {j+1}\"\n",
    "            prompt += f\"\\nArticle:\\n{train_data_agnews[fse_index]['text']}\"\n",
    "            prompt += f\"\\nTopic:\\n{label_names[lbl]}\"\n",
    "\n",
    "        # Add target example (guaranteed not remove_label due to filtering)\n",
    "        prompt += f\"\\n\\nExample {len(fse_indices)+1}\"\n",
    "        prompt += f\"\\nArticle:\\n{train_data_agnews[tq_index]['text']}\"\n",
    "        prompt += f\"\\nTopic:\\n{label_names[int(train_data_agnews[tq_index]['label'])]}\"\n",
    "\n",
    "        all_prompts['agnews_controlled'].append(\n",
    "            \"<bos><start_of_turn>user\\n\" + prompt\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f4c60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_idx in range(1500):\n",
    "    assert all_prompts['agnews'][example_idx].split('Article:')[-1] == all_prompts['agnews_controlled'][example_idx].split('Article:')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf7267",
   "metadata": {},
   "source": [
    "# Load SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e70640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_all_hooks(model: torch.nn.Module):\n",
    "    for module in model.modules():\n",
    "        module._forward_hooks.clear()\n",
    "        module._forward_pre_hooks.clear()\n",
    "        module._backward_hooks.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0c2516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def sae_logits_before_jumprelu(sae, x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns encoder pre-activations (\"logits\") for a SAELens JumpReLUSAE.\n",
    "\n",
    "    x can be shape:\n",
    "      - (d_in,)\n",
    "      - (seq, d_in)\n",
    "      - (batch, seq, d_in)\n",
    "\n",
    "    Output will be the same shape but with last dim = d_sae.\n",
    "    \"\"\"\n",
    "    # Ensure correct device/dtype (optional but usually helpful)\n",
    "    x = x.to(device=sae.device, dtype=sae.dtype)\n",
    "\n",
    "    # Use SAELens preprocessing (handles b_dec-to-input and any norm/reshape logic)\n",
    "    sae_in = sae.process_sae_in(x)\n",
    "\n",
    "    # Pre-activations (this is what you want)\n",
    "    hidden_pre = sae_in @ sae.W_enc + sae.b_enc\n",
    "\n",
    "    # Match SAELens exactly if hooks are present (usually identity unless you attached hooks)\n",
    "    if hasattr(sae, \"hook_sae_acts_pre\"):\n",
    "        hidden_pre = sae.hook_sae_acts_pre(hidden_pre)\n",
    "\n",
    "    return hidden_pre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "833216e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_decoding_embeddings(sae, layer_idx):\n",
    "    def hook(module, inputs, output):\n",
    "        # For Residual SAEs: output[0] is [Batch, Seq, Hidden]\n",
    "        x = output[0]\n",
    "        \n",
    "        global feature_summary_trajectories\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # logits shape: [Batch, Seq, Num_Features]\n",
    "#             activations =sae.encode(x)\n",
    "            logits = sae_logits_before_jumprelu(sae, x)\n",
    "            \n",
    "#             assert activations.size() == logits.size()\n",
    "            \n",
    "            for b, ex_idx in enumerate(CURRENT_BATCH_EXAMPLE_IDXS):\n",
    "#                 start_pos = example_summary[task_type][i][ex_idx]['analysis_start']\n",
    "                \n",
    "                # Considering (k-2, k)\n",
    "                start_pos = example_summary[task_type][ex_idx]['target_example_start']\n",
    "                end_pos = lengths[b]\n",
    "                \n",
    "                xxx = logits[b, start_pos:end_pos].clone().cpu().float() # [Seq, Feat]\n",
    "                feature_summary_trajectories[task_type].append(xxx)\n",
    "                \n",
    "        return output\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72cd0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_decoding_embeddings_activation(sae, layer_idx):\n",
    "    def hook(module, inputs, output):\n",
    "        # For Residual SAEs: output[0] is [Batch, Seq, Hidden]\n",
    "        x = output[0]\n",
    "        \n",
    "        global feature_summary_trajectories\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # logits shape: [Batch, Seq, Num_Features]\n",
    "            activations =sae.encode(x)\n",
    "#             logits = sae_logits_before_jumprelu(sae, x)\n",
    "            \n",
    "            for b, ex_idx in enumerate(CURRENT_BATCH_EXAMPLE_IDXS):\n",
    "#                 start_pos = example_summary[task_type][i][ex_idx]['analysis_start']\n",
    "                \n",
    "                # Considering (k-2, k)\n",
    "                start_pos = example_summary[task_type][N][ex_idx]['target_example_start']\n",
    "                end_pos = lengths[b]\n",
    "                \n",
    "                xxx = activations[b, start_pos:end_pos].clone().cpu().float() # [Seq, Feat]\n",
    "                feature_summary_trajectories[task_type][N].append(xxx)\n",
    "                \n",
    "        return output\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4bfd7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_143830/1821212839.py:9: DeprecationWarning: Unpacking SAE objects is deprecated. SAE.from_pretrained() now returns only the SAE object. Use SAE.from_pretrained_with_cfg_and_sparsity() to get the config dict and sparsity as well.\n",
      "  sae, sae_config, sparsity = SAE.from_pretrained(\n"
     ]
    }
   ],
   "source": [
    "from sae_lens import SAE\n",
    "\n",
    "clear_all_hooks(model)\n",
    "\n",
    "sae_set = {}\n",
    "target_layer = 15\n",
    "\n",
    "for layer_idx in range(target_layer,target_layer+1):\n",
    "    sae, sae_config, sparsity = SAE.from_pretrained(\n",
    "        release=\"llama_scope_lxr_8x\", \n",
    "        sae_id=f\"l{layer_idx}r_8x\",    # Tuned-Lens trained their model based on the input of the layer. Therefore, the correct corresponding SAE is layer_idx-1 \n",
    "        device=\"cuda\"\n",
    "    )\n",
    "    sae_set[layer_idx] = sae\n",
    "    target_steering_block = model.get_submodule(f\"model.layers.{layer_idx}\")\n",
    "    target_steering_block._forward_hooks.clear()\n",
    "    steering_hook = target_steering_block.register_forward_hook(extract_decoding_embeddings(sae=sae, layer_idx = layer_idx))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490016d",
   "metadata": {},
   "source": [
    "# 1. Using AGNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a63d9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_summary_peak_max = {}\n",
    "feature_summary_peak_min = {}\n",
    "feature_summary_trajectories = {}\n",
    "example_summary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f30dce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = 'agnews'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9663dbe",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b574c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "feature_summary_trajectories= {}\n",
    "example_summary = {}\n",
    "example_summary[task_type] = {}\n",
    "feature_summary_trajectories[task_type] = []\n",
    "\n",
    "num_examples = len(all_prompts[task_type])\n",
    "\n",
    "for batch_start in range(0, num_examples, BATCH_SIZE):\n",
    "    batch_prompts = all_prompts[task_type][batch_start: batch_start + BATCH_SIZE]\n",
    "    batch_size_actual = len(batch_prompts)\n",
    "\n",
    "    print(f\"{task_type}, {N}-shot, batch_start={batch_start}, batch_size={batch_size_actual}\")\n",
    "\n",
    "    if batch_start == 0:\n",
    "        print(\"First prompt in this N-shot setting:\\n\", batch_prompts[0])\n",
    "\n",
    "    enc = tokenizer(\n",
    "        batch_prompts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,               # <-- batching\n",
    "        truncation=False,\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "    input_ids = enc[\"input_ids\"].to(model.device)\n",
    "    attention_mask = enc[\"attention_mask\"].to(model.device)\n",
    "\n",
    "    res = {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"input_masks\": attention_mask,\n",
    "    }\n",
    "\n",
    "    lengths = attention_mask.sum(dim=1).tolist()\n",
    "\n",
    "    for b in range(batch_size_actual):\n",
    "        example_idx = batch_start + b\n",
    "        L = lengths[b]\n",
    "\n",
    "        decoded_tokens = [\n",
    "            tokenizer.decode(int(input_ids[b, j]))\n",
    "            for j in range(L)\n",
    "        ]\n",
    "\n",
    "        Example_start = []\n",
    "        analysis_start = 0\n",
    "        for j in range(max(0, L - 2)):\n",
    "            if (\n",
    "                decoded_tokens[j] == 'Article'\n",
    "                and decoded_tokens[j + 1] == ':\\n'\n",
    "            ):\n",
    "                Example_start.append(j)\n",
    "\n",
    "            if (\n",
    "                decoded_tokens[j] == 'Example'\n",
    "                and decoded_tokens[j+1] == '1'\n",
    "            ):\n",
    "                analysis_start = j\n",
    "        \n",
    "        assert len(Example_start) == N + 1\n",
    "        example_summary[task_type][example_idx] = {'All_tokens': L,\n",
    "                                                   'target_example_start': Example_start[-1],\n",
    "                                                   'tq_label': decoded_tokens[-1]}\n",
    "        if example_idx == 0:\n",
    "            print(\"Example summary for example_idx=0:\\n\", example_summary[task_type][example_idx])\n",
    "\n",
    "\n",
    "\n",
    "    CURRENT_BATCH_EXAMPLE_IDXS = list(range(batch_start, batch_start + batch_size_actual))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            res[\"input_ids\"],\n",
    "            attention_mask=res[\"input_masks\"],\n",
    "            max_new_tokens=1,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61b0169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_decoding_embeddings_controlled(sae, layer_idx):\n",
    "    def hook(module, inputs, output):\n",
    "        # For Residual SAEs: output[0] is [Batch, Seq, Hidden]\n",
    "        x = output[0]\n",
    "        \n",
    "        global feature_summary_trajectories_controlled\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # logits shape: [Batch, Seq, Num_Features]\n",
    "            activations =sae.encode(x)\n",
    "            logits = sae_logits_before_jumprelu(sae, x)\n",
    "            \n",
    "            assert activations.size() == logits.size()\n",
    "            \n",
    "            for b, ex_idx in enumerate(CURRENT_BATCH_EXAMPLE_IDXS):\n",
    "#                 start_pos = example_summary[task_type][i][ex_idx]['analysis_start']\n",
    "                \n",
    "                # Considering (k-2, k)\n",
    "                start_pos = example_summary_controlled[task_type][ex_idx]['target_example_start']\n",
    "                end_pos = lengths[b]\n",
    "                \n",
    "                xxx = logits[b, start_pos:end_pos].clone().cpu().float() # [Seq, Feat]\n",
    "                feature_summary_trajectories_controlled[task_type].append(xxx)\n",
    "                \n",
    "        return output\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6f9aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import SAE\n",
    "\n",
    "clear_all_hooks(model)\n",
    "\n",
    "for layer_idx in range(target_layer,target_layer+1):\n",
    "    target_steering_block = model.get_submodule(f\"model.layers.{layer_idx}\")\n",
    "    target_steering_block._forward_hooks.clear()\n",
    "    steering_hook = target_steering_block.register_forward_hook(extract_decoding_embeddings_controlled(sae=sae, layer_idx = layer_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "feature_summary_trajectories_controlled = {}\n",
    "example_summary_controlled= {}\n",
    "\n",
    "feature_summary_trajectories_controlled[task_type] = []\n",
    "example_summary_controlled[task_type] = {}\n",
    "\n",
    "\n",
    "num_examples = len(all_prompts[task_type+'_controlled'])\n",
    "\n",
    "for batch_start in range(0, num_examples, BATCH_SIZE):\n",
    "    batch_prompts = all_prompts[task_type+'_controlled'][batch_start: batch_start + BATCH_SIZE]\n",
    "    batch_size_actual = len(batch_prompts)\n",
    "\n",
    "    print(f\"{task_type}, {N}-shot, batch_start={batch_start}, batch_size={batch_size_actual}\")\n",
    "\n",
    "    if batch_start == 0:\n",
    "        print(\"First prompt in this N-shot setting:\\n\", batch_prompts[0])\n",
    "\n",
    "    enc = tokenizer(\n",
    "        batch_prompts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,               # <-- batching\n",
    "        truncation=False,\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "    input_ids = enc[\"input_ids\"].to(model.device)\n",
    "    attention_mask = enc[\"attention_mask\"].to(model.device)\n",
    "\n",
    "    res = {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"input_masks\": attention_mask,\n",
    "    }\n",
    "\n",
    "    lengths = attention_mask.sum(dim=1).tolist()\n",
    "\n",
    "    for b in range(batch_size_actual):\n",
    "        example_idx = batch_start + b\n",
    "        L = lengths[b]\n",
    "\n",
    "        decoded_tokens = [\n",
    "            tokenizer.decode(int(input_ids[b, j]))\n",
    "            for j in range(L)\n",
    "        ]\n",
    "\n",
    "        Example_start = []\n",
    "        analysis_start = 0\n",
    "        for j in range(max(0, L - 2)):\n",
    "            if (\n",
    "                decoded_tokens[j] == 'Article'\n",
    "                and decoded_tokens[j + 1] == ':\\n'\n",
    "            ):\n",
    "                Example_start.append(j)\n",
    "\n",
    "            if (\n",
    "                decoded_tokens[j] == 'Example'\n",
    "                and decoded_tokens[j+1] == '1'\n",
    "            ):\n",
    "                analysis_start = j\n",
    "        \n",
    "        assert len(Example_start) == N+1\n",
    "        example_summary_controlled[task_type][example_idx] = {'All_tokens': L,\n",
    "                                                              'target_example_start': Example_start[-1],\n",
    "                                                              'tq_label': decoded_tokens[-1]}\n",
    "        if example_idx == 0:\n",
    "            print(\"Example summary for example_idx=0:\\n\", example_summary_controlled[task_type][example_idx])\n",
    "\n",
    "\n",
    "\n",
    "    CURRENT_BATCH_EXAMPLE_IDXS = list(range(batch_start, batch_start + batch_size_actual))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            res[\"input_ids\"],\n",
    "            attention_mask=res[\"input_masks\"],\n",
    "            max_new_tokens=1,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "824da084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_all_feature_negations(W_dec):\n",
    "    \"\"\"\n",
    "    Returns a dictionary mapping EVERY feature to its most negative partner.\n",
    "    \"\"\"\n",
    "    # 1. Normalize\n",
    "    norms = torch.norm(W_dec, dim=1, keepdim=True)\n",
    "    W_norm = W_dec / (norms + 1e-8)\n",
    "    \n",
    "    # 2. Compute Similarity Matrix\n",
    "    # [16384, 16384]\n",
    "    cos_sim_matrix = torch.mm(W_norm, W_norm.t())\n",
    "    \n",
    "    # 3. Mask the diagonal (Self-similarity is 1.0, we want negatives)\n",
    "    # We fill diagonal with infinity so it doesn't interfere with finding the min\n",
    "    cos_sim_matrix.fill_diagonal_(float('inf'))\n",
    "    \n",
    "    # 4. Find the min (most negative) for EVERY row at once\n",
    "    # values: [16384] (the correlation score)\n",
    "    # indices: [16384] (the index of the partner feature)\n",
    "    min_values, min_indices = torch.min(cos_sim_matrix, dim=1)\n",
    "    \n",
    "    # 5. Build the dictionary\n",
    "    all_features_map = {}\n",
    "    \n",
    "    for i in range(W_dec.shape[0]):\n",
    "        all_features_map[i] = {\n",
    "            'pair_feature': min_indices[i].item(),\n",
    "            'sim': min_values[i].item()\n",
    "        }\n",
    "        \n",
    "    print(f\"Processed {len(all_features_map)} features.\")\n",
    "    return all_features_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8e6a420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 32768 features.\n"
     ]
    }
   ],
   "source": [
    "all_feature_map = get_all_feature_negations(sae.W_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf5a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_k_tokens = 5\n",
    "\n",
    "Label_wise_logit = []\n",
    "example_level_score = []\n",
    "for example_idx in range(len(feature_summary_trajectories[task_type])):\n",
    "    example_level_score.append(feature_summary_trajectories[task_type][example_idx][-last_k_tokens:-1].clone())\n",
    "\n",
    "example_level_score = torch.stack(example_level_score)\n",
    "example_level_score = torch.mean(example_level_score, dim=1)\n",
    "\n",
    "discriminative_mode = {}\n",
    "for label in range(4):\n",
    "    label_avg = torch.mean(example_level_score[num_examples_per_label * label: num_examples_per_label * (label+1)], dim=0)\n",
    "    Label_wise_logit.append(label_avg.clone())\n",
    "\n",
    "Label_wise_logit = torch.stack(Label_wise_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1899cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 0\n",
    "\n",
    "vals, inds = torch.topk(Label_wise_logit[label], k=200)\n",
    "for val, ind in zip(vals, inds):\n",
    "    print(f\"Feature {ind} (Antipodality: {all_feature_map[int(ind)]['sim']: .3f}): Avg.Logit: {val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782f3d70",
   "metadata": {},
   "source": [
    "# 1. Label-Specific Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ed36e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_selective_features = {}\n",
    "for target_label in range(4):\n",
    "    label_selective_features[target_label] = {}\n",
    "\n",
    "    target_label_selective_features = {}\n",
    "\n",
    "    for feat in range(len(Label_wise_logit[target_label])):\n",
    "        a = [Label_wise_logit[item][feat] for item in range(4)]\n",
    "\n",
    "        a.sort()\n",
    "        if Label_wise_logit[target_label][feat] == a[-1]:\n",
    "            target_label_selective_features[feat] = float(a[-1] - a[-2])\n",
    "            \n",
    "    target_label_selective_features = {k:v for k,v in sorted(target_label_selective_features.items(),\n",
    "                                                         key=lambda item:item[1], reverse= True)}\n",
    "    \n",
    "    label_selective_features[target_label] = target_label_selective_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05d2ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open('./label_selective_features_L31.json', 'w') as file:\n",
    "#     json.dump(label_selective_features, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8622cbcb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86d0ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_k_tokens = 5\n",
    "\n",
    "Label_wise_logit_controlled = []\n",
    "example_level_score_controlled = []\n",
    "for example_idx in range(len(feature_summary_trajectories_controlled[task_type])):\n",
    "    example_level_score_controlled.append(feature_summary_trajectories_controlled[task_type][example_idx][-last_k_tokens:-1].clone())\n",
    "\n",
    "example_level_score_controlled = torch.stack(example_level_score_controlled)\n",
    "example_level_score_controlled = torch.mean(example_level_score_controlled, dim=1)\n",
    "\n",
    "discriminative_mode = {}\n",
    "for label in range(num_labels):\n",
    "    label_avg = torch.mean(example_level_score_controlled[num_examples_per_label * label: num_examples_per_label * (label+1)], dim=0)\n",
    "    Label_wise_logit_controlled.append(label_avg.clone())\n",
    "\n",
    "Label_wise_logit_controlled = torch.stack(Label_wise_logit_controlled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7de223e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plasticity_candidates = {}\n",
    "\n",
    "for feat in range(sae.W_dec.size(0)):\n",
    "    plasticity_candidates[feat] = {}\n",
    "    \n",
    "    \n",
    "label = 0\n",
    "\n",
    "vals, inds = torch.topk(Label_wise_logit_controlled[label], k=200)\n",
    "for feat in range(sae.W_dec.size(0)):\n",
    "    plasticity_candidates[feat][label] = Label_wise_logit_controlled[label][feat] - Label_wise_logit[label][feat]\n",
    "    \n",
    "    \n",
    "label = 1\n",
    "vals, inds = torch.topk(Label_wise_logit_controlled[label], k=200)\n",
    "\n",
    "for feat in range(sae.W_dec.size(0)):\n",
    "    plasticity_candidates[feat][label] = Label_wise_logit_controlled[label][feat] - Label_wise_logit[label][feat]\n",
    "    \n",
    "\n",
    "label = 2\n",
    "vals, inds = torch.topk(Label_wise_logit_controlled[label], k=200)\n",
    "\n",
    "for feat in range(sae.W_dec.size(0)):\n",
    "    plasticity_candidates[feat][label] = Label_wise_logit_controlled[label][feat] - Label_wise_logit[label][feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15512f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = remove_label\n",
    "topk = 100\n",
    "\n",
    "top_k_label_selective_features = list(label_selective_features[target_label].keys())[:topk]\n",
    "\n",
    "for feat in top_k_label_selective_features:\n",
    "    print('='*77)\n",
    "    print(f\"Feature {feat} (Antipodality: {all_feature_map[feat]['sim']: .3f})\")\n",
    "    print(f\"* Increase in Logit toward the rest labels: {plasticity_candidates[feat][0]+plasticity_candidates[feat][1]+plasticity_candidates[feat][2]:.3f}\")\n",
    "    print('-'*77)\n",
    "    print(f\"* Original Tech-Score: {Label_wise_logit[target_label][feat]: .3f}\")\n",
    "    for label in range(3):\n",
    "        print(f'* Label {label}, Orig Score: {Label_wise_logit[label][feat]: .3f} -> {Label_wise_logit_controlled[label][feat]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca88f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plasticity_candidates = {k:v for k,v in sorted(plasticity_candidates.items(),\n",
    "                                               key=lambda item:item[1][0]+item[1][1]+item[1][2], reverse= True)}\n",
    "\n",
    "for i, feat in enumerate(plasticity_candidates.keys()):\n",
    "    if i == 500:break\n",
    "    print('-'*77)\n",
    "    print(f\"Feature {feat} (Antipodality: {all_feature_map[feat]['sim']: .3f})\")\n",
    "    for label in range(3):\n",
    "        print('label:', label)\n",
    "        print(f\"* Diff: {plasticity_candidates[feat][label]: .3f}\")\n",
    "        print(f\"* Controlled Logit: {Label_wise_logit_controlled[label][feat]}\")\n",
    "        print(f\"* Original Logit: {Label_wise_logit[label][feat]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "caf84bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "@torch.no_grad()\n",
    "def volcano_plot_cohensd_wilcoxon(\n",
    "    example_level_score: torch.Tensor,                # [2000, 16384]\n",
    "    example_level_score_controlled: torch.Tensor,     # [1500, 16384]\n",
    "    feature_indices=None,                             # None => all; or list/1D tensor of feature ids\n",
    "    condition1_name=\"Original\",\n",
    "    condition2_name=\"Controlled\",\n",
    "    p_thresh=0.01,\n",
    "    chunk_size=2048,                                  # for Wilcoxon batching\n",
    "    alternative=\"two-sided\",                           # wilcoxon alternative\n",
    "    title=\"Volcano plot: Cohen's d vs Wilcoxon p-value\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        fig: plotly figure\n",
    "        results: dict with keys ['feature_idx','cohens_d','pvalue']\n",
    "    \"\"\"\n",
    "\n",
    "    n = int(example_level_score_controlled.shape[0])   # 1500\n",
    "    assert example_level_score.shape[0] >= n, \"example_level_score must have at least 1500 rows.\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1) Build paired differences\n",
    "    # ----------------------------\n",
    "    # diff = condition1 - condition2 over aligned examples\n",
    "    diff = (example_level_score_controlled.detach().cpu().float()\n",
    "            - example_level_score[:n].detach().cpu().float())   # [n, F]\n",
    "\n",
    "    F = diff.shape[1]\n",
    "\n",
    "    # Select features if provided\n",
    "    if feature_indices is None:\n",
    "        feat_idx = np.arange(F, dtype=np.int32)\n",
    "        diff_sel = diff  # [n, F]\n",
    "    else:\n",
    "        if torch.is_tensor(feature_indices):\n",
    "            feat_idx = feature_indices.detach().cpu().numpy().astype(np.int32)\n",
    "        else:\n",
    "            feat_idx = np.asarray(feature_indices, dtype=np.int32)\n",
    "        diff_sel = diff[:, feat_idx]  # [n, K]\n",
    "\n",
    "    K = diff_sel.shape[1]\n",
    "\n",
    "    # ----------------------------\n",
    "    # 2) Cohen's d (paired): mean(diff)/std(diff)\n",
    "    # ----------------------------\n",
    "    mean_diff = diff_sel.mean(dim=0)                            # [K]\n",
    "    std_diff  = diff_sel.std(dim=0, unbiased=True).clamp_min(1e-12)\n",
    "    cohens_d  = (mean_diff / std_diff).numpy()                  # [K]\n",
    "\n",
    "    # ----------------------------\n",
    "    # 3) Wilcoxon signed-rank p-values per feature (vectorized by chunks)\n",
    "    # ----------------------------\n",
    "    diff_np = diff_sel.numpy()  # [n, K], float32\n",
    "    pvals = np.ones(K, dtype=np.float64)\n",
    "\n",
    "    for start in range(0, K, chunk_size):\n",
    "        end = min(K, start + chunk_size)\n",
    "        sub = diff_np[:, start:end]  # [n, chunk]\n",
    "\n",
    "        # Columns with at least one nonzero difference; otherwise wilcoxon errors\n",
    "        nonzero_cols = (sub != 0).any(axis=0)\n",
    "\n",
    "        if np.any(nonzero_cols):\n",
    "            res = wilcoxon(\n",
    "                sub[:, nonzero_cols],\n",
    "                axis=0,\n",
    "                zero_method=\"wilcox\",\n",
    "                alternative=alternative,\n",
    "                method=\"approx\"   # fast + appropriate for n=1500\n",
    "            )\n",
    "            pvals[start:end][nonzero_cols] = np.asarray(res.pvalue, dtype=np.float64)\n",
    "\n",
    "        # all-zero columns remain p=1\n",
    "\n",
    "    # ----------------------------\n",
    "    # 4) Volcano plot (p-value on log scale, reversed)\n",
    "    # ----------------------------\n",
    "    # Significance masks\n",
    "    sig = pvals < p_thresh\n",
    "    pos = sig & (cohens_d > 0)\n",
    "    neg = sig & (cohens_d < 0)\n",
    "    ns  = ~sig\n",
    "\n",
    "    def make_hover_text(idxs):\n",
    "        return [\n",
    "            f\"feature={int(feat_idx[i])}<br>\"\n",
    "            f\"cohen_d={cohens_d[i]:+.4f}<br>\"\n",
    "            f\"p={pvals[i]:.3e}\"\n",
    "            for i in idxs\n",
    "        ]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Nonsignificant\n",
    "    ns_idx = np.where(ns)[0]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cohens_d[ns_idx],\n",
    "        y=pvals[ns_idx],\n",
    "        mode=\"markers\",\n",
    "        name=f\"p ≥ {p_thresh}\",\n",
    "        text=make_hover_text(ns_idx),\n",
    "        hoverinfo=\"text\",\n",
    "        marker=dict(size=6, opacity=0.45),\n",
    "    ))\n",
    "\n",
    "    # Significant negative\n",
    "    neg_idx = np.where(neg)[0]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cohens_d[neg_idx],\n",
    "        y=pvals[neg_idx],\n",
    "        mode=\"markers\",\n",
    "        name=f\"p < {p_thresh} & d < 0\",\n",
    "        text=make_hover_text(neg_idx),\n",
    "        hoverinfo=\"text\",\n",
    "        marker=dict(size=7, opacity=0.85),\n",
    "    ))\n",
    "\n",
    "    # Significant positive\n",
    "    pos_idx = np.where(pos)[0]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cohens_d[pos_idx],\n",
    "        y=pvals[pos_idx],\n",
    "        mode=\"markers\",\n",
    "        name=f\"p < {p_thresh} & d > 0\",\n",
    "        text=make_hover_text(pos_idx),\n",
    "        hoverinfo=\"text\",\n",
    "        marker=dict(size=7, opacity=0.85),\n",
    "    ))\n",
    "\n",
    "    # Reference lines\n",
    "    fig.add_vline(x=0.0, line_width=2, line_dash=\"dash\", line_color=\"black\")\n",
    "    fig.add_hline(y=p_thresh, line_width=2, line_dash=\"dash\", line_color=\"red\")\n",
    "\n",
    "    # Layout: log p-values, reversed so smaller p is higher (volcano-like)\n",
    "    fig.update_layout(\n",
    "        title=f\"{title}<br><sup>{condition1_name} − {condition2_name} (paired over {n} aligned examples)</sup>\",\n",
    "        xaxis_title=\"Cohen's d (paired; dz)  =  mean(diff)/std(diff), diff = controlled - original\",\n",
    "        yaxis_title=\"Wilcoxon signed-rank p-value (log scale)\",\n",
    "#         template=\"plotly_white\",\n",
    "        hovermode=\"closest\",\n",
    "        legend=dict(orientation=\"v\", yanchor=\"top\", y=0.98, xanchor=\"right\", x=0.98),\n",
    "    )\n",
    "    fig.update_yaxes(type=\"log\", autorange=\"reversed\")\n",
    "\n",
    "    results = {\n",
    "        \"feature_idx\": feat_idx,     # length K\n",
    "        \"cohens_d\": cohens_d,        # length K\n",
    "        \"pvalue\": pvals,             # length K\n",
    "    }\n",
    "\n",
    "    return fig, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49284ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, results = volcano_plot_cohensd_wilcoxon(\n",
    "    example_level_score,\n",
    "    example_level_score_controlled,\n",
    "    feature_indices=None,   # all features\n",
    "    p_thresh=0.01,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7413ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, results = volcano_plot_cohensd_wilcoxon(\n",
    "    example_level_score,\n",
    "    example_level_score_controlled,\n",
    "    feature_indices=top_k_label_selective_features,   # all features\n",
    "    p_thresh=0.01,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "880103aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97370267\n",
      "1.70709796054656e-175\n"
     ]
    }
   ],
   "source": [
    "feature = 16189\n",
    "idx = list(results['feature_idx']).index(feature)\n",
    "print(results['cohens_d'][idx])\n",
    "print(results['pvalue'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49c48fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import wilcoxon, norm\n",
    "\n",
    "@torch.no_grad()\n",
    "def volcano_plot_rankbiserial_wilcoxon(\n",
    "    example_level_score: torch.Tensor,                # [2000, 16384]\n",
    "    example_level_score_controlled: torch.Tensor,     # [1500, 16384] aligned with first 1500\n",
    "    feature_indices=None,                             # None => all; or list/1D tensor of feature ids\n",
    "    condition1_name=\"Original\",\n",
    "    condition2_name=\"Controlled\",\n",
    "    p_thresh=0.01,\n",
    "    chunk_size=2048,\n",
    "    title=\"Volcano plot: Rank-biserial vs Wilcoxon p-value\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Paired comparison (aligned examples):\n",
    "        diff = original - controlled\n",
    "\n",
    "    x-axis: rank-biserial correlation (paired Wilcoxon signed-rank)\n",
    "    y-axis: two-sided Wilcoxon p-value (log scale, reversed)\n",
    "    \"\"\"\n",
    "\n",
    "    n = int(example_level_score_controlled.shape[0])  # e.g. 1500\n",
    "    assert example_level_score.shape[0] >= n, \"example_level_score must have at least n rows.\"\n",
    "\n",
    "    # diff: [n, F]\n",
    "    diff = (example_level_score_controlled.detach().cpu().float()\n",
    "            - example_level_score[:n].detach().cpu().float())\n",
    "\n",
    "    F = diff.shape[1]\n",
    "\n",
    "    # Feature selection\n",
    "    if feature_indices is None:\n",
    "        feat_idx = np.arange(F, dtype=np.int32)\n",
    "        diff_sel = diff\n",
    "    else:\n",
    "        if torch.is_tensor(feature_indices):\n",
    "            feat_idx = feature_indices.detach().cpu().numpy().astype(np.int32)\n",
    "        else:\n",
    "            feat_idx = np.asarray(feature_indices, dtype=np.int32)\n",
    "        diff_sel = diff[:, feat_idx]\n",
    "\n",
    "    K = diff_sel.shape[1]\n",
    "    diff_np = diff_sel.numpy()  # [n, K]\n",
    "\n",
    "    # Outputs\n",
    "    pvals = np.ones(K, dtype=np.float64)\n",
    "    r_rb  = np.full(K, np.nan, dtype=np.float64)\n",
    "\n",
    "    for start in range(0, K, chunk_size):\n",
    "        end = min(K, start + chunk_size)\n",
    "        sub = diff_np[:, start:end]  # [n, chunk]\n",
    "\n",
    "        # Columns with any nonzero diffs (Wilcoxon errors if all zeros)\n",
    "        nonzero_cols = (sub != 0).any(axis=0)\n",
    "\n",
    "        if not np.any(nonzero_cols):\n",
    "            continue\n",
    "\n",
    "        sub_nz = sub[:, nonzero_cols]  # [n, chunk_nz]\n",
    "\n",
    "        # n_eff per feature (drop zeros, matching zero_method=\"wilcox\")\n",
    "        n_eff = (sub_nz != 0).sum(axis=0).astype(np.float64)  # [chunk_nz]\n",
    "        R = n_eff * (n_eff + 1.0) / 2.0                       # sum of ranks, [chunk_nz]\n",
    "\n",
    "        # One Wilcoxon call gives W+ and z (approx). We then compute two-sided p from z.\n",
    "        res = wilcoxon(\n",
    "            sub_nz,\n",
    "            axis=0,\n",
    "            zero_method=\"wilcox\",\n",
    "            alternative=\"greater\",   # makes statistic = W+ (sum of + ranks)\n",
    "            method=\"approx\"\n",
    "        )\n",
    "\n",
    "        Wplus = np.asarray(res.statistic, dtype=np.float64)    # [chunk_nz]\n",
    "        z     = np.asarray(res.zstatistic, dtype=np.float64)   # [chunk_nz]\n",
    "\n",
    "        # Two-sided p-value from z\n",
    "        p_two = 2.0 * norm.sf(np.abs(z))                       # [chunk_nz]\n",
    "        p_two = np.clip(p_two, 0.0, 1.0)\n",
    "\n",
    "        # Rank-biserial: 2W+/R - 1 (undefined if R==0)\n",
    "        r = np.full_like(Wplus, np.nan, dtype=np.float64)\n",
    "        ok = R > 0\n",
    "        r[ok] = (2.0 * Wplus[ok] / R[ok]) - 1.0\n",
    "\n",
    "        # Write back to full arrays\n",
    "        idxs = np.where(nonzero_cols)[0]                       # positions within this chunk\n",
    "        pvals[start:end][idxs] = p_two\n",
    "        r_rb[start:end][idxs]  = r\n",
    "\n",
    "    # Masks for plotting\n",
    "    finite = np.isfinite(r_rb) & np.isfinite(pvals)\n",
    "    sig = finite & (pvals < p_thresh)\n",
    "    pos = sig & (r_rb > 0)\n",
    "    neg = sig & (r_rb < 0)\n",
    "    ns  = finite & (~sig)\n",
    "\n",
    "    def hover_text(idxs):\n",
    "        return [\n",
    "            f\"feature={int(feat_idx[i])}<br>\"\n",
    "            f\"rank_biserial={r_rb[i]:+.4f}<br>\"\n",
    "            f\"p={pvals[i]:.3e}\"\n",
    "            for i in idxs\n",
    "        ]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    ns_idx = np.where(ns)[0]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=r_rb[ns_idx], y=pvals[ns_idx],\n",
    "        mode=\"markers\",\n",
    "        name=f\"p ≥ {p_thresh}\",\n",
    "        text=hover_text(ns_idx),\n",
    "        hoverinfo=\"text\",\n",
    "        marker=dict(size=6, opacity=0.45),\n",
    "    ))\n",
    "\n",
    "    neg_idx = np.where(neg)[0]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=r_rb[neg_idx], y=pvals[neg_idx],\n",
    "        mode=\"markers\",\n",
    "        name=f\"p < {p_thresh} & r < 0\",\n",
    "        text=hover_text(neg_idx),\n",
    "        hoverinfo=\"text\",\n",
    "        marker=dict(size=7, opacity=0.85),\n",
    "    ))\n",
    "\n",
    "    pos_idx = np.where(pos)[0]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=r_rb[pos_idx], y=pvals[pos_idx],\n",
    "        mode=\"markers\",\n",
    "        name=f\"p < {p_thresh} & r > 0\",\n",
    "        text=hover_text(pos_idx),\n",
    "        hoverinfo=\"text\",\n",
    "        marker=dict(size=7, opacity=0.85),\n",
    "    ))\n",
    "\n",
    "    # Reference lines\n",
    "    fig.add_vline(x=0.0, line_width=2, line_dash=\"dash\", line_color=\"black\")\n",
    "    fig.add_hline(y=p_thresh, line_width=2, line_dash=\"dash\", line_color=\"red\")\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"{title}<br><sup>{condition1_name} − {condition2_name} (paired over {n} aligned examples)</sup>\",\n",
    "        xaxis_title=\"Rank-biserial correlation (paired Wilcoxon signed-rank)\",\n",
    "        yaxis_title=\"Two-sided Wilcoxon p-value (log scale)\",\n",
    "        template=\"plotly_white\",\n",
    "        hovermode=\"closest\",\n",
    "        legend=dict(orientation=\"v\", yanchor=\"top\", y=0.98, xanchor=\"right\", x=0.98),\n",
    "    )\n",
    "\n",
    "    # “Volcano-like” p-value axis: log scale + reversed so small p is high\n",
    "    fig.update_yaxes(type=\"log\", autorange=\"reversed\")\n",
    "\n",
    "    results = {\n",
    "        \"feature_idx\": feat_idx,      # length K\n",
    "        \"rank_biserial\": r_rb,        # length K\n",
    "        \"pvalue\": pvals,              # length K\n",
    "    }\n",
    "    return fig, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0caaa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, results = volcano_plot_rankbiserial_wilcoxon(\n",
    "    example_level_score=example_level_score,\n",
    "    example_level_score_controlled=example_level_score_controlled,\n",
    "    feature_indices=top_k_label_selective_features,\n",
    "    condition1_name=\"Full prompt\",\n",
    "    condition2_name=\"Controlled (label removed)\",\n",
    "    p_thresh=0.01,\n",
    "    chunk_size=2048,\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ec9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 16189\n",
    "idx = list(results['feature_idx']).index(feature)\n",
    "print(results['rank_biserial'][idx])\n",
    "print(results['pvalue'][idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
